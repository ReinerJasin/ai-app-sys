{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBTnXAL7MDDiRX58m/FJSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReinerJasin/ai-app-sys/blob/main/week6(sess2)_12224827.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the tensorflow"
      ],
      "metadata": {
        "id": "GTRQwH2RxcUh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n9qZmuxjvsXV",
        "outputId": "86bba410-1bb0-4348-8503-4e41f4523778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.5\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.1)\n",
            "Collecting h5py<=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.48.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.1.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=7a15f2cdf3a061b1c42d4ed9c0644e98826c2b5e1c2ce62229db1b306885f6eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: numpy, h5py, tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "jaxlib 0.3.15+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.17 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 h5py-2.10.0 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install tensorflow==1.15.5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies"
      ],
      "metadata": {
        "id": "cHi4ZTlmxhqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from urllib import request\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2"
      ],
      "metadata": {
        "id": "oqMCgv9Tw3Ak"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read csv file using np.loadtxt"
      ],
      "metadata": {
        "id": "faBMrKeKxkdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_database = np.loadtxt('fashion-mnist_train.csv', delimiter=',', skiprows=1)[:,1:]\n",
        "# Looking at the shape of the file\n",
        "print(img_database.shape)\n",
        "\n",
        "total_num_images = (img_database.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTB3Uxx-xjss",
        "outputId": "5c958a8c-521c-48e8-c075-ffcd098d3700"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the parameter for Neural Network"
      ],
      "metadata": {
        "id": "s66mLkFjx8nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = 784 # Input image size is 28 x 28\n",
        "hidden_layer_1 = 256\n",
        "hidden_layer_2 = 32\n",
        "hidden_layer_3 = 32\n",
        "hidden_layer_4 = 256\n",
        "output_layer = 784 # Same as the n_input dimension\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "# Define the placeholders\n",
        "X = tf.placeholder(tf.float32, [None, n_input])\n",
        "Y = tf.placeholder(tf.float32, [None, output_layer])"
      ],
      "metadata": {
        "id": "ftiSkk-Mx_xW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the weight and bias"
      ],
      "metadata": {
        "id": "z5sEn_nezR7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight and Bias definitions of Neural Network\n",
        "Weight_NN = {\"W1\": tf.Variable(tf.random_normal([n_input, hidden_layer_1])),\n",
        "             \"W2\": tf.Variable(tf.random_normal([hidden_layer_1, hidden_layer_2])),\n",
        "             \"W3\": tf.Variable(tf.random_normal([hidden_layer_2, hidden_layer_3])),\n",
        "             \"W4\": tf.Variable(tf.random_normal([hidden_layer_3, hidden_layer_4])),\n",
        "             \"W5\": tf.Variable(tf.random_normal([hidden_layer_4, output_layer])),\n",
        "             }\n",
        "\n",
        "Bias_NN = {\"B1\": tf.Variable(tf.random_normal([hidden_layer_1])),\n",
        "           \"B2\": tf.Variable(tf.random_normal([hidden_layer_2])),\n",
        "           \"B3\": tf.Variable(tf.random_normal([hidden_layer_3])),\n",
        "           \"B4\": tf.Variable(tf.random_normal([hidden_layer_4])),\n",
        "           \"B5\": tf.Variable(tf.random_normal([output_layer])),\n",
        "           }"
      ],
      "metadata": {
        "id": "o66lcw1pzTij"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the computational Graph"
      ],
      "metadata": {
        "id": "SzoQzNBr0DIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network\n",
        "Z1 = tf.add(tf.matmul(X, Weight_NN[\"W1\"]), Bias_NN[\"B1\"])\n",
        "Z1_out = tf.nn.sigmoid(Z1)\n",
        "\n",
        "Z2 = tf.add(tf.matmul(Z1_out, Weight_NN[\"W2\"]), Bias_NN[\"B2\"])\n",
        "Z2_out = tf.nn.sigmoid(Z2)\n",
        "\n",
        "Z3 = tf.add(tf.matmul(Z2_out, Weight_NN[\"W3\"]), Bias_NN[\"B3\"])\n",
        "Z3_out = tf.nn.sigmoid(Z3)\n",
        "\n",
        "Z4 = tf.add(tf.matmul(Z3_out, Weight_NN[\"W4\"]), Bias_NN[\"B4\"])\n",
        "Z4_out = tf.nn.sigmoid(Z4)\n",
        "\n",
        "Z5 = tf.add(tf.matmul(Z4_out, Weight_NN[\"W5\"]), Bias_NN[\"B5\"])\n",
        "Z5_out = tf.nn.sigmoid(Z5)"
      ],
      "metadata": {
        "id": "rzaTpiIJ0GCV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Neural Network model using TensorFlow API"
      ],
      "metadata": {
        "id": "GMj8Z9Nt06iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z1 = tf.layers.dense(X, hidden_layer_1, activation = tf.nn.sigmoid)\n",
        "Z2 = tf.layers.dense(Z1, hidden_layer_2, activation = tf.nn.sigmoid)\n",
        "Z3 = tf.layers.dense(Z1, hidden_layer_3, activation = tf.nn.sigmoid)\n",
        "Z4 = tf.layers.dense(Z1, hidden_layer_4, activation = tf.nn.sigmoid)\n",
        "NN_output = tf.layers.dense(Z4, output_layer)"
      ],
      "metadata": {
        "id": "YQF2HoRZ0-RG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling the dataset to avoid bias, adding noise by 10"
      ],
      "metadata": {
        "id": "j58IV3Of1kKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset\n",
        "np.random.shuffle(img_database)\n",
        "\n",
        "X_train = img_database\n",
        "\n",
        "# Normalize the dataset\n",
        "X_train = X_train\n",
        "\n",
        "# Create a noisy dataset\n",
        "X_train_noisy = X_train + 10 * np.random.normal(0, 1, size = X_train.shape)\n",
        "\n",
        "# Original image\n",
        "plt.imshow(X_train[0].reshape(28, 28), cmap = 'gray')\n",
        "plt.show()\n",
        "\n",
        "# Noisy image\n",
        "plt.imshow(X_train_noisy[0].reshape(28,28), cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "EaRvSsPR1pri",
        "outputId": "faa2c694-db37-4cb8-e504-2722fe285c98"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the metrics"
      ],
      "metadata": {
        "id": "bvb6DhDk2o3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The loss function\n",
        "computed_loss = tf.reduce_mean(tf.square(NN_output-Y))\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(computed_loss)\n",
        "\n",
        "# Initialize the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-hd52cE2sCS",
        "outputId": "648dfb2e-f4a0-4a2e-8bab-4e640c28fc9b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the session"
      ],
      "metadata": {
        "id": "dyP5dfQz3Zb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "for epoch in range(epochs):\n",
        "  for i in range(int(total_num_images/batch_size)):\n",
        "    X_epoch = X_train[i * batch_size : (i+1) * batch_size]\n",
        "    X_noise_epoch = X_train_noisy[i * batch_size : (i+1) * batch_size]\n",
        "    _, loss = sess.run([optimizer, computed_loss], feed_dict = {X: X_noise_epoch, Y: X_epoch})\n",
        "  print('Epoch', epoch, '/', epochs, 'loss', loss)\n",
        "\n",
        "# Pick any image\n",
        "X_actual = X_train[:10]\n",
        "noisy_image = X_train_noisy[:10]\n",
        "\n",
        "# Run it through the autoencoder\n",
        "denoised_image = sess.run(NN_output, feed_dict={X:noisy_image})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnyUpkGO3atn",
        "outputId": "9992b10c-e56f-4504-b682-eaf87487ec1e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 / 100 loss 4401.1846\n",
            "Epoch 1 / 100 loss 4124.2275\n",
            "Epoch 2 / 100 loss 3731.4285\n",
            "Epoch 3 / 100 loss 3567.8054\n",
            "Epoch 4 / 100 loss 3650.1624\n",
            "Epoch 5 / 100 loss 3428.387\n",
            "Epoch 6 / 100 loss 3446.4143\n",
            "Epoch 7 / 100 loss 3382.4712\n",
            "Epoch 8 / 100 loss 3287.777\n",
            "Epoch 9 / 100 loss 3261.5527\n",
            "Epoch 10 / 100 loss 3177.7866\n",
            "Epoch 11 / 100 loss 3207.6016\n",
            "Epoch 12 / 100 loss 3153.7244\n",
            "Epoch 13 / 100 loss 3096.594\n",
            "Epoch 14 / 100 loss 3098.4202\n",
            "Epoch 15 / 100 loss 3034.2036\n",
            "Epoch 16 / 100 loss 3003.378\n",
            "Epoch 17 / 100 loss 3030.1775\n",
            "Epoch 18 / 100 loss 3003.5327\n",
            "Epoch 19 / 100 loss 3034.0989\n",
            "Epoch 20 / 100 loss 2937.1604\n",
            "Epoch 21 / 100 loss 3001.8264\n",
            "Epoch 22 / 100 loss 3002.4136\n",
            "Epoch 23 / 100 loss 3061.7817\n",
            "Epoch 24 / 100 loss 2943.4119\n",
            "Epoch 25 / 100 loss 2987.926\n",
            "Epoch 26 / 100 loss 2921.0017\n",
            "Epoch 27 / 100 loss 2864.7976\n",
            "Epoch 28 / 100 loss 2838.705\n",
            "Epoch 29 / 100 loss 2833.2617\n",
            "Epoch 30 / 100 loss 2900.0586\n",
            "Epoch 31 / 100 loss 2862.1873\n",
            "Epoch 32 / 100 loss 2786.2566\n",
            "Epoch 33 / 100 loss 2835.9575\n",
            "Epoch 34 / 100 loss 2873.884\n",
            "Epoch 35 / 100 loss 2849.5068\n",
            "Epoch 36 / 100 loss 2799.966\n",
            "Epoch 37 / 100 loss 2842.7644\n",
            "Epoch 38 / 100 loss 2808.0454\n",
            "Epoch 39 / 100 loss 2798.3525\n",
            "Epoch 40 / 100 loss 2741.5083\n",
            "Epoch 41 / 100 loss 2710.2146\n",
            "Epoch 42 / 100 loss 2866.7039\n",
            "Epoch 43 / 100 loss 2714.174\n",
            "Epoch 44 / 100 loss 2781.005\n",
            "Epoch 45 / 100 loss 2805.0303\n",
            "Epoch 46 / 100 loss 2717.6272\n",
            "Epoch 47 / 100 loss 2710.833\n",
            "Epoch 48 / 100 loss 2721.872\n",
            "Epoch 49 / 100 loss 2657.726\n",
            "Epoch 50 / 100 loss 2653.4878\n",
            "Epoch 51 / 100 loss 2654.517\n",
            "Epoch 52 / 100 loss 2659.2366\n",
            "Epoch 53 / 100 loss 2691.8474\n",
            "Epoch 54 / 100 loss 2704.1096\n",
            "Epoch 55 / 100 loss 2694.6462\n",
            "Epoch 56 / 100 loss 2652.9944\n",
            "Epoch 57 / 100 loss 2661.2778\n",
            "Epoch 58 / 100 loss 2602.9714\n",
            "Epoch 59 / 100 loss 2627.3997\n",
            "Epoch 60 / 100 loss 2699.156\n",
            "Epoch 61 / 100 loss 2585.053\n",
            "Epoch 62 / 100 loss 2638.9695\n",
            "Epoch 63 / 100 loss 2613.681\n",
            "Epoch 64 / 100 loss 2571.1934\n",
            "Epoch 65 / 100 loss 2527.2727\n",
            "Epoch 66 / 100 loss 2658.3137\n",
            "Epoch 67 / 100 loss 2555.564\n",
            "Epoch 68 / 100 loss 2515.998\n",
            "Epoch 69 / 100 loss 2555.369\n",
            "Epoch 70 / 100 loss 2527.9868\n",
            "Epoch 71 / 100 loss 2529.7278\n",
            "Epoch 72 / 100 loss 2506.89\n",
            "Epoch 73 / 100 loss 2520.7285\n",
            "Epoch 74 / 100 loss 2528.5383\n",
            "Epoch 75 / 100 loss 2548.4302\n",
            "Epoch 76 / 100 loss 2602.093\n",
            "Epoch 77 / 100 loss 2494.1914\n",
            "Epoch 78 / 100 loss 2554.9102\n",
            "Epoch 79 / 100 loss 2585.7478\n",
            "Epoch 80 / 100 loss 2552.6174\n",
            "Epoch 81 / 100 loss 2517.8704\n",
            "Epoch 82 / 100 loss 2528.5715\n",
            "Epoch 83 / 100 loss 2526.2083\n",
            "Epoch 84 / 100 loss 2505.5305\n",
            "Epoch 85 / 100 loss 2501.722\n",
            "Epoch 86 / 100 loss 2475.5007\n",
            "Epoch 87 / 100 loss 2513.985\n",
            "Epoch 88 / 100 loss 2571.353\n",
            "Epoch 89 / 100 loss 2482.8157\n",
            "Epoch 90 / 100 loss 2500.4236\n",
            "Epoch 91 / 100 loss 2451.6416\n",
            "Epoch 92 / 100 loss 2506.048\n",
            "Epoch 93 / 100 loss 2501.1262\n",
            "Epoch 94 / 100 loss 2473.293\n",
            "Epoch 95 / 100 loss 2497.5886\n",
            "Epoch 96 / 100 loss 2475.7747\n",
            "Epoch 97 / 100 loss 2507.129\n",
            "Epoch 98 / 100 loss 2507.625\n",
            "Epoch 99 / 100 loss 2440.147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second way to initializing the session"
      ],
      "metadata": {
        "id": "h7lVagbd4bIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way of running session\n",
        "\n",
        "X_aztual = X_train[:10]\n",
        "noisy_image = X_train_noisy[:10]\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(int(total_num_images/batch_size)):\n",
        "      X_epoch = X_train[i * batch_size : (i*1) * batch_size]\n",
        "      X_noise_epoch = X_train_noisy[i * batch_size : (i*1)*batch_size]\n",
        "      _, loss = sess.run([optimizer, computed_loss], feed_dict = {X: X_noise_epoch, Y: X_epoch})\n",
        "    print('Epoch', epoch, '/', epochs, 'loss:', loss)\n",
        "  denoised_image = sess.run(NN_output, feed_dict = {X: noisy_image})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7jIOIL74dgK",
        "outputId": "9a5ae9a5-bffb-4da1-ab1d-2e57abd774b7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 / 100 loss: nan\n",
            "Epoch 1 / 100 loss: nan\n",
            "Epoch 2 / 100 loss: nan\n",
            "Epoch 3 / 100 loss: nan\n",
            "Epoch 4 / 100 loss: nan\n",
            "Epoch 5 / 100 loss: nan\n",
            "Epoch 6 / 100 loss: nan\n",
            "Epoch 7 / 100 loss: nan\n",
            "Epoch 8 / 100 loss: nan\n",
            "Epoch 9 / 100 loss: nan\n",
            "Epoch 10 / 100 loss: nan\n",
            "Epoch 11 / 100 loss: nan\n",
            "Epoch 12 / 100 loss: nan\n",
            "Epoch 13 / 100 loss: nan\n",
            "Epoch 14 / 100 loss: nan\n",
            "Epoch 15 / 100 loss: nan\n",
            "Epoch 16 / 100 loss: nan\n",
            "Epoch 17 / 100 loss: nan\n",
            "Epoch 18 / 100 loss: nan\n",
            "Epoch 19 / 100 loss: nan\n",
            "Epoch 20 / 100 loss: nan\n",
            "Epoch 21 / 100 loss: nan\n",
            "Epoch 22 / 100 loss: nan\n",
            "Epoch 23 / 100 loss: nan\n",
            "Epoch 24 / 100 loss: nan\n",
            "Epoch 25 / 100 loss: nan\n",
            "Epoch 26 / 100 loss: nan\n",
            "Epoch 27 / 100 loss: nan\n",
            "Epoch 28 / 100 loss: nan\n",
            "Epoch 29 / 100 loss: nan\n",
            "Epoch 30 / 100 loss: nan\n",
            "Epoch 31 / 100 loss: nan\n",
            "Epoch 32 / 100 loss: nan\n",
            "Epoch 33 / 100 loss: nan\n",
            "Epoch 34 / 100 loss: nan\n",
            "Epoch 35 / 100 loss: nan\n",
            "Epoch 36 / 100 loss: nan\n",
            "Epoch 37 / 100 loss: nan\n",
            "Epoch 38 / 100 loss: nan\n",
            "Epoch 39 / 100 loss: nan\n",
            "Epoch 40 / 100 loss: nan\n",
            "Epoch 41 / 100 loss: nan\n",
            "Epoch 42 / 100 loss: nan\n",
            "Epoch 43 / 100 loss: nan\n",
            "Epoch 44 / 100 loss: nan\n",
            "Epoch 45 / 100 loss: nan\n",
            "Epoch 46 / 100 loss: nan\n",
            "Epoch 47 / 100 loss: nan\n",
            "Epoch 48 / 100 loss: nan\n",
            "Epoch 49 / 100 loss: nan\n",
            "Epoch 50 / 100 loss: nan\n",
            "Epoch 51 / 100 loss: nan\n",
            "Epoch 52 / 100 loss: nan\n",
            "Epoch 53 / 100 loss: nan\n",
            "Epoch 54 / 100 loss: nan\n",
            "Epoch 55 / 100 loss: nan\n",
            "Epoch 56 / 100 loss: nan\n",
            "Epoch 57 / 100 loss: nan\n",
            "Epoch 58 / 100 loss: nan\n",
            "Epoch 59 / 100 loss: nan\n",
            "Epoch 60 / 100 loss: nan\n",
            "Epoch 61 / 100 loss: nan\n",
            "Epoch 62 / 100 loss: nan\n",
            "Epoch 63 / 100 loss: nan\n",
            "Epoch 64 / 100 loss: nan\n",
            "Epoch 65 / 100 loss: nan\n",
            "Epoch 66 / 100 loss: nan\n",
            "Epoch 67 / 100 loss: nan\n",
            "Epoch 68 / 100 loss: nan\n",
            "Epoch 69 / 100 loss: nan\n",
            "Epoch 70 / 100 loss: nan\n",
            "Epoch 71 / 100 loss: nan\n",
            "Epoch 72 / 100 loss: nan\n",
            "Epoch 73 / 100 loss: nan\n",
            "Epoch 74 / 100 loss: nan\n",
            "Epoch 75 / 100 loss: nan\n",
            "Epoch 76 / 100 loss: nan\n",
            "Epoch 77 / 100 loss: nan\n",
            "Epoch 78 / 100 loss: nan\n",
            "Epoch 79 / 100 loss: nan\n",
            "Epoch 80 / 100 loss: nan\n",
            "Epoch 81 / 100 loss: nan\n",
            "Epoch 82 / 100 loss: nan\n",
            "Epoch 83 / 100 loss: nan\n",
            "Epoch 84 / 100 loss: nan\n",
            "Epoch 85 / 100 loss: nan\n",
            "Epoch 86 / 100 loss: nan\n",
            "Epoch 87 / 100 loss: nan\n",
            "Epoch 88 / 100 loss: nan\n",
            "Epoch 89 / 100 loss: nan\n",
            "Epoch 90 / 100 loss: nan\n",
            "Epoch 91 / 100 loss: nan\n",
            "Epoch 92 / 100 loss: nan\n",
            "Epoch 93 / 100 loss: nan\n",
            "Epoch 94 / 100 loss: nan\n",
            "Epoch 95 / 100 loss: nan\n",
            "Epoch 96 / 100 loss: nan\n",
            "Epoch 97 / 100 loss: nan\n",
            "Epoch 98 / 100 loss: nan\n",
            "Epoch 99 / 100 loss: nan\n"
          ]
        }
      ]
    }
  ]
}